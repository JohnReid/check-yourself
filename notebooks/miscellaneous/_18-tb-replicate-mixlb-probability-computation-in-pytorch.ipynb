{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "The purpose of this notebook is to replicate notebook `_09-tb-Calculate-lognormal-MIXL-probs` using the pytorch implementation of MIXLB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.sparse as sparse\n",
    "import pandas as pd\n",
    "\n",
    "import pylogit as pl\n",
    "import pylogit.mixed_logit_calcs as mlc\n",
    "import pylogit.choice_tools as ct\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "import src.models.mixlb as mixlb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv(\"../../data/processed/model_ready_car_data.csv\")\n",
    "forecast_df = pd.read_csv(\"../../data/processed/forecast_car_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate the MNL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specification and name dictionaries\n",
    "mnl_spec, mnl_names = OrderedDict(), OrderedDict()\n",
    "\n",
    "orig_cols_and_display_names =\\\n",
    "    [(\"neg_price_over_log_income\", 'Neg Price over log(income)'),\n",
    "     ('range_over_100', 'Range (units: 100mi)'),\n",
    "     (\"neg_acceleration_over_10\", 'Neg Acceleration (units: 0.1sec)'),\n",
    "     ('top_speed_over_100', 'Neg Top speed (units: 0.01mph)'),\n",
    "     (\"neg_pollution\", 'Neg Pollution'),\n",
    "     ('vehicle_size_over_10', 'Size'),\n",
    "     ('big_enough', 'Big enough'),\n",
    "     ('luggage_space', 'Luggage space'),\n",
    "     (\"neg_tens_of_cents_per_mile\", 'Neg Operation cost'),\n",
    "     ('station_availability', 'Station availability'),\n",
    "     ('sports_utility_vehicle', 'Sports utility vehicle'),\n",
    "     ('sports_car', 'Sports car'),\n",
    "     ('station_wagon', 'Station wagon'),\n",
    "     ('truck', 'Truck'),\n",
    "     ('van', 'Van'),\n",
    "     ('electric', 'EV'),\n",
    "     ('electric_commute_lte_5mi', 'Commute < 5 & EV'),\n",
    "     ('electric_and_college', 'College & EV'),\n",
    "     ('compressed_natural_gas', 'CNG'),\n",
    "     ('methanol', 'Methanol'),\n",
    "     ('methanol_and_college', 'College & Methanol'),\n",
    "     ('non_ev', 'Non Electric-Vehicle'),\n",
    "     ('non_cng', 'Non Compressed Natural Gas')]\n",
    "\n",
    "for col, display_name in orig_cols_and_display_names:\n",
    "    mnl_spec[col] = 'all_same'\n",
    "    mnl_names[col] = display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -8,338.8486\n",
      "Initial Log-likelihood: -8,338.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/pylogit/choice_tools.py:703: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  design_matrix = np.hstack((x[:, None] for x in independent_vars))\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/optimize/_minimize.py:511: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.20 seconds.\n",
      "Final log-likelihood: -7,391.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/pylogit/base_multinomial_cm_v2.py:1228: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self._store_inferential_results(np.sqrt(np.diag(self.cov)),\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multinomial Logit Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>choice</td>          <th>  No. Observations:  </th>    <td>4,654</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>         <td>Multinomial Logit Model</td> <th>  Df Residuals:      </th>    <td>4,631</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>           <th>  Df Model:          </th>     <td>23</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 10 Jun 2020</td>     <th>  Pseudo R-squ.:     </th>    <td>0.114</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:16:54</td>         <th>  Pseudo R-bar-squ.: </th>    <td>0.111</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AIC:</th>                 <td>14,829.660</td>        <th>  Log-Likelihood:    </th> <td>-7,391.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIC:</th>                 <td>14,977.906</td>        <th>  LL-Null:           </th> <td>-8,338.849</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Price over log(income)</th>       <td>    0.1854</td> <td>    0.027</td> <td>    6.796</td> <td> 0.000</td> <td>    0.132</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Range (units: 100mi)</th>             <td>    0.3501</td> <td>    0.027</td> <td>   13.052</td> <td> 0.000</td> <td>    0.298</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Acceleration (units: 0.1sec)</th> <td>    0.7160</td> <td>    0.111</td> <td>    6.472</td> <td> 0.000</td> <td>    0.499</td> <td>    0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Top speed (units: 0.01mph)</th>   <td>    0.2612</td> <td>    0.081</td> <td>    3.228</td> <td> 0.001</td> <td>    0.103</td> <td>    0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Pollution</th>                    <td>    0.4441</td> <td>    0.102</td> <td>    4.367</td> <td> 0.000</td> <td>    0.245</td> <td>    0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Size</th>                             <td>    0.9345</td> <td>    0.316</td> <td>    2.953</td> <td> 0.003</td> <td>    0.314</td> <td>    1.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Big enough</th>                       <td>    0.1432</td> <td>    0.077</td> <td>    1.853</td> <td> 0.064</td> <td>   -0.008</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Luggage space</th>                    <td>    0.5009</td> <td>    0.191</td> <td>    2.623</td> <td> 0.009</td> <td>    0.127</td> <td>    0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Operation cost</th>               <td>    0.7679</td> <td>    0.076</td> <td>   10.131</td> <td> 0.000</td> <td>    0.619</td> <td>    0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Station availability</th>             <td>    0.4133</td> <td>    0.096</td> <td>    4.294</td> <td> 0.000</td> <td>    0.225</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sports utility vehicle</th>           <td>    0.8201</td> <td>    0.141</td> <td>    5.830</td> <td> 0.000</td> <td>    0.544</td> <td>    1.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sports car</th>                       <td>    0.6370</td> <td>    0.148</td> <td>    4.298</td> <td> 0.000</td> <td>    0.347</td> <td>    0.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Station wagon</th>                    <td>   -1.4367</td> <td>    0.062</td> <td>  -23.139</td> <td> 0.000</td> <td>   -1.558</td> <td>   -1.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Truck</th>                            <td>   -1.0168</td> <td>    0.049</td> <td>  -20.753</td> <td> 0.000</td> <td>   -1.113</td> <td>   -0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Van</th>                              <td>   -0.7989</td> <td>    0.047</td> <td>  -16.864</td> <td> 0.000</td> <td>   -0.892</td> <td>   -0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EV</th>                               <td>   -0.1786</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Commute < 5 & EV</th>                 <td>    0.1983</td> <td>    0.084</td> <td>    2.374</td> <td> 0.018</td> <td>    0.035</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>College & EV</th>                     <td>    0.4426</td> <td>    0.109</td> <td>    4.058</td> <td> 0.000</td> <td>    0.229</td> <td>    0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CNG</th>                              <td>    0.3450</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Methanol</th>                         <td>    0.3134</td> <td>    0.103</td> <td>    3.051</td> <td> 0.002</td> <td>    0.112</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>College & Methanol</th>               <td>    0.2284</td> <td>    0.089</td> <td>    2.576</td> <td> 0.010</td> <td>    0.055</td> <td>    0.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Non Electric-Vehicle</th>             <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Non Compressed Natural Gas</th>       <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                     Multinomial Logit Model Regression Results                    \n",
       "===================================================================================\n",
       "Dep. Variable:                      choice   No. Observations:                4,654\n",
       "Model:             Multinomial Logit Model   Df Residuals:                    4,631\n",
       "Method:                                MLE   Df Model:                           23\n",
       "Date:                     Wed, 10 Jun 2020   Pseudo R-squ.:                   0.114\n",
       "Time:                             11:16:54   Pseudo R-bar-squ.:               0.111\n",
       "AIC:                            14,829.660   Log-Likelihood:             -7,391.830\n",
       "BIC:                            14,977.906   LL-Null:                    -8,338.849\n",
       "====================================================================================================\n",
       "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Neg Price over log(income)           0.1854      0.027      6.796      0.000       0.132       0.239\n",
       "Range (units: 100mi)                 0.3501      0.027     13.052      0.000       0.298       0.403\n",
       "Neg Acceleration (units: 0.1sec)     0.7160      0.111      6.472      0.000       0.499       0.933\n",
       "Neg Top speed (units: 0.01mph)       0.2612      0.081      3.228      0.001       0.103       0.420\n",
       "Neg Pollution                        0.4441      0.102      4.367      0.000       0.245       0.643\n",
       "Size                                 0.9345      0.316      2.953      0.003       0.314       1.555\n",
       "Big enough                           0.1432      0.077      1.853      0.064      -0.008       0.295\n",
       "Luggage space                        0.5009      0.191      2.623      0.009       0.127       0.875\n",
       "Neg Operation cost                   0.7679      0.076     10.131      0.000       0.619       0.916\n",
       "Station availability                 0.4133      0.096      4.294      0.000       0.225       0.602\n",
       "Sports utility vehicle               0.8201      0.141      5.830      0.000       0.544       1.096\n",
       "Sports car                           0.6370      0.148      4.298      0.000       0.347       0.928\n",
       "Station wagon                       -1.4367      0.062    -23.139      0.000      -1.558      -1.315\n",
       "Truck                               -1.0168      0.049    -20.753      0.000      -1.113      -0.921\n",
       "Van                                 -0.7989      0.047    -16.864      0.000      -0.892      -0.706\n",
       "EV                                  -0.1786        nan        nan        nan         nan         nan\n",
       "Commute < 5 & EV                     0.1983      0.084      2.374      0.018       0.035       0.362\n",
       "College & EV                         0.4426      0.109      4.058      0.000       0.229       0.656\n",
       "CNG                                  0.3450        nan        nan        nan         nan         nan\n",
       "Methanol                             0.3134      0.103      3.051      0.002       0.112       0.515\n",
       "College & Methanol                   0.2284      0.089      2.576      0.010       0.055       0.402\n",
       "Non Electric-Vehicle                      0        nan        nan        nan         nan         nan\n",
       "Non Compressed Natural Gas                0        nan        nan        nan         nan         nan\n",
       "====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate an mnl with the same basic specification as the MIXL.\n",
    "mnl_model =\\\n",
    "    pl.create_choice_model(data=car_df,\n",
    "                           alt_id_col='alt_id',\n",
    "                           obs_id_col='obs_id',\n",
    "                           choice_col='choice',\n",
    "                           specification=mnl_spec,\n",
    "                           model_type='MNL',\n",
    "                           names=mnl_names)\n",
    "\n",
    "mnl_model.fit_mle(np.zeros(len(mnl_names)),\n",
    "                  constrained_pos=[-2, -1])\n",
    "\n",
    "# Look at the estimation results\n",
    "mnl_model.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Create a model object mnl with the same basic specification as the MIXL.\n",
    "# To be used later to extract the design matrix\n",
    "forecast_model =\\\n",
    "    pl.create_choice_model(data=forecast_df,\n",
    "                           alt_id_col='alt_id',\n",
    "                           obs_id_col='obs_id',\n",
    "                           choice_col='choice',\n",
    "                           specification=mnl_spec,\n",
    "                           model_type='MNL',\n",
    "                           names=mnl_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the MIXL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "mixl_model = mixlb.MIXLB()\n",
    "\n",
    "# Set the model parameters to the final estimates from Brownstone & Train (1998),\n",
    "# taking care of the typo from the published paper.\n",
    "mean_array =\\\n",
    "    np.array([-1.5983748481622846, #-5.999,\n",
    "              -0.877,\n",
    "              -0.302,\n",
    "              -1.364,\n",
    "              -0.711,\n",
    "               1.541,\n",
    "              -1.748,\n",
    "               1.563,\n",
    "              -0.071,\n",
    "              -0.741,\n",
    "               0.897,\n",
    "               0.698,\n",
    "              -1.508,\n",
    "              -1.094,\n",
    "              -0.819,\n",
    "              -0.905,\n",
    "               0.359,\n",
    "               0.770,\n",
    "               0.621,\n",
    "               0.476,\n",
    "               0.335,\n",
    "               0,\n",
    "               0])\n",
    "\n",
    "std_dev_array =\\\n",
    "    np.array([6.808, 5.380, 2.289, 0.971])\n",
    "\n",
    "paper_estimates_array =\\\n",
    "    np.concatenate((mean_array, std_dev_array), axis=0)\n",
    "mixl_model.set_params_numpy(paper_estimates_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create arguments to calculate model probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_mapping_torch(id_array):\n",
    "    mapping_scipy =\\\n",
    "        ct.create_sparse_mapping(id_array).tocoo()\n",
    "    torch_mapping_indices =\\\n",
    "        torch.LongTensor(torch.from_numpy(\n",
    "            np.concatenate((mapping_scipy.row[None, :],\n",
    "                            mapping_scipy.col[None, :]),\n",
    "                           axis=0).astype(np.int_)))\n",
    "    torch_mapping_values =\\\n",
    "        (torch.from_numpy(mapping_scipy.data.astype(np.float32))\n",
    "              .double())\n",
    "    num_rows = mapping_scipy.data.size\n",
    "    num_cols = ct.get_original_order_unique_ids(id_array).size\n",
    "    mapping_torch =\\\n",
    "        sparse.FloatTensor(\n",
    "            torch_mapping_indices,\n",
    "            torch_mapping_values,\n",
    "            torch.Size([num_rows, num_cols]))\n",
    "    return mapping_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the design matrix from the original and forecast data\n",
    "orig_design_matrix_np = mnl_model.design\n",
    "orig_design_matrix =\\\n",
    "    torch.tensor(orig_design_matrix_np.astype(np.float32))\n",
    "\n",
    "\n",
    "forecast_design_np = forecast_model.design\n",
    "forecast_design_matrix =\\\n",
    "    torch.tensor(forecast_design_np.astype(np.float32))\n",
    "\n",
    "# Get the rows_to_obs and rows_to_mixers matrices.\n",
    "rows_to_obs =\\\n",
    "    create_sparse_mapping_torch(car_df[mnl_model.obs_id_col].values)\n",
    "rows_to_mixers =\\\n",
    "    create_sparse_mapping_torch(car_df[mnl_model.obs_id_col].values)\n",
    "\n",
    "\n",
    "\n",
    "####\n",
    "# Get the normal random variates.\n",
    "####\n",
    "# Determine the number of draws being used for the mixed logit\n",
    "num_draws = 250\n",
    "# Determine the number of observations with randomly distributed\n",
    "# sensitivities\n",
    "num_mixers = car_df.obs_id.unique().size\n",
    "\n",
    "# Get the random draws needed for the draws of each coeffcient\n",
    "# Each element in the list will be a 2D ndarray of shape\n",
    "# num_mixers by num_draws\n",
    "normal_rvs_list_np =\\\n",
    "    mlc.get_normal_draws(num_mixers,\n",
    "                         num_draws,\n",
    "                         mixl_model.design_info.num_mixing_vars,\n",
    "                         seed=601)\n",
    "normal_rvs_list = [torch.from_numpy(x).double() for x in normal_rvs_list_np]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare MIXL probabilities to MNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-7370.0864, dtype=torch.float64, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the MIXL probabilities\n",
    "mixl_probs =\\\n",
    "    mixl_model.forward(design_2d=orig_design_matrix,\n",
    "                       rows_to_obs=rows_to_obs,\n",
    "                       rows_to_mixers=rows_to_mixers,\n",
    "                       normal_rvs_list=normal_rvs_list)\n",
    "# Compute the MIXL log-likelihood\n",
    "torch_choices =\\\n",
    "    torch.from_numpy(mnl_model.choices.astype(np.float32)).double()\n",
    "mixl_log_likelihood =\\\n",
    "    torch.sum(torch_choices * torch.log(mixl_probs))\n",
    "mixl_log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIXL: -7,370.09\n",
      "MNL:  -7,391.83\n"
     ]
    }
   ],
   "source": [
    "# Compare the MIXL to MNL log-likelihoods\n",
    "msg = 'MIXL: {:,.2f}\\nMNL:  {:,.2f}'\n",
    "print(msg.format(mixl_log_likelihood.item(), mnl_model.llf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients:\n",
      "[  0.52739913  16.80788119  -2.03877212  -1.5663477   -4.6216078\n",
      "   0.34231704   0.18036642   3.63172369  -2.92595559   4.3653854\n",
      "   1.12133433  -0.70962555   0.82817194  -0.70474704   2.46969284\n",
      "   0.677335     0.69274961   0.4105395  -34.60967672  29.33451904\n",
      "  22.59093556  -0.677335    34.60967672   0.10889218  -1.29851708\n",
      "   0.89968333  -4.38320548]\n",
      "\n",
      "Any NaN probabilities? False\n",
      "\n",
      "count    27924.000000\n",
      "mean         0.166667\n",
      "std          0.111085\n",
      "min          0.008662\n",
      "25%          0.080818\n",
      "50%          0.135765\n",
      "75%          0.228371\n",
      "max          0.646645\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Compute the gradients\n",
    "mixl_log_likelihood.backward()\n",
    "# Extract the gradients\n",
    "paper_gradients = mixl_model.get_grad_numpy()\n",
    "print('Gradients:\\n{}'.format(paper_gradients))\n",
    "# Zero the gradients as if we were performing optimization\n",
    "mixl_model.zero_grad()\n",
    "# Extract the probabilities as an array\n",
    "mixl_probs_array = mixl_probs.detach().numpy()\n",
    "# Make sure none of the predicted probabilities are NaN\n",
    "msg = '\\nAny NaN probabilities? {}\\n'\n",
    "print(msg.format(np.isnan(mixl_probs_array).any()))\n",
    "# Describe the computed probabilities\n",
    "print(pd.Series(mixl_probs_array).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the forecast probabilities\n",
    "forecast_probs =\\\n",
    "    mixl_model.forward(design_2d=forecast_design_matrix,\n",
    "                       rows_to_obs=rows_to_obs,\n",
    "                       rows_to_mixers=rows_to_mixers,\n",
    "                       normal_rvs_list=normal_rvs_list)\n",
    "# Zero the gradients as if we were performing optimization\n",
    "mixl_model.zero_grad()\n",
    "# Extract the probabilities as an array\n",
    "forecast_probs_array = forecast_probs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 stupid forecasts\n",
      "The predicted change in market share of large gas cars is -12.205%\n"
     ]
    }
   ],
   "source": [
    "# Ensure the forecast probabilities for large gas cars are\n",
    "# higher than the original probabilities for large gas cars\n",
    "large_gas_car_idx = ((car_df['body_type'] == 'regcar') &\n",
    "                     (car_df['vehicle_size'] == 3) &\n",
    "                     (car_df['fuel_type'] == 'gasoline')).values\n",
    "num_stupid_forecasts =\\\n",
    "    ((forecast_probs_array > mixl_probs_array)[large_gas_car_idx]).sum()\n",
    "print(\"{:,} stupid forecasts\".format(num_stupid_forecasts))\n",
    "\n",
    "# Look at the mixed logits predicted change in the market share\n",
    "# of large gas cars after the price increase.\n",
    "large_gas_car_share_change =\\\n",
    "    (((forecast_probs_array[large_gas_car_idx]).sum() -\n",
    "     (mixl_probs_array[large_gas_car_idx]).sum()) /\n",
    "     (mixl_probs_array[large_gas_car_idx]).sum())\n",
    "msg = 'The predicted change in market share of large gas cars is {:.3%}'\n",
    "print(msg.format(large_gas_car_share_change))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "The most unexpected finding was that none of the parameter gradients was near zero.\n",
    "\n",
    "This implies that the parameters that maximize the simulated log-likelihood function may be far from the current parameters.\n",
    "\n",
    "Who knows if the true maximum likelihood parameters will result in a predictive model with the same qualitative findings."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
