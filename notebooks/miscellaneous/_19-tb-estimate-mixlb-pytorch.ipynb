{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "The purpose of this notebook is estimate the \"Mixed Logit B\" model of Brownstone and Train (1998) using pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare paths to where data is or should be stored\n",
    "DATA_PATH =\\\n",
    "    \"../../data/processed/model_ready_car_data.csv\"\n",
    "\n",
    "OUTPUT_PARAM_PATH =\\\n",
    "    \"../../models/estimated_mixlb_parameters.csv\"\n",
    "\n",
    "OUTPUT_GRADIENT_PATH =\\\n",
    "    \"../../models/estimated_mixlb_gradient.csv\"\n",
    "\n",
    "OUTPUT_HESSIAN_PATH =\\\n",
    "    \"../../models/estimated_mixlb_hessian.csv\"\n",
    "\n",
    "# Note needed column names\n",
    "ALT_ID_COLUMN = 'alt_id'\n",
    "OBS_ID_COLUMN = 'obs_id'\n",
    "CHOICE_COLUMN = 'choice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 0,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Built-in modules\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Third-party modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import pylogit as pl\n",
    "import pylogit.mixed_logit_calcs as mlc\n",
    "\n",
    "# Local modules\n",
    "sys.path.insert(0, '../../')\n",
    "import src.models.mixlb as mixlb\n",
    "import src.models.torch_utils as utils\n",
    "from src.hessian import hessian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df = pd.read_csv(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the corresponding MNL model\n",
    "Create a MNL model that has the same design matrix as Mixed Logit B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specification and name dictionaries\n",
    "mnl_spec, mnl_names = OrderedDict(), OrderedDict()\n",
    "\n",
    "for col, display_name in mixlb.DESIGN_TO_DISPLAY_DICT.items():\n",
    "    mnl_spec[col] = 'all_same'\n",
    "    mnl_names[col] = display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-likelihood at zero: -8,338.8486\n",
      "Initial Log-likelihood: -8,338.8486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/pylogit/choice_tools.py:703: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  design_matrix = np.hstack((x[:, None] for x in independent_vars))\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/optimize/_minimize.py:511: RuntimeWarning: Method BFGS does not use Hessian information (hess).\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time for Point Estimation: 0.18 seconds.\n",
      "Final log-likelihood: -7,391.8300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/pylogit/base_multinomial_cm_v2.py:1228: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self._store_inferential_results(np.sqrt(np.diag(self.cov)),\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/Users/timothyb0912/minimamba/envs/checkYourself/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Multinomial Logit Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>choice</td>          <th>  No. Observations:  </th>    <td>4,654</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>         <td>Multinomial Logit Model</td> <th>  Df Residuals:      </th>    <td>4,631</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                  <td>MLE</td>           <th>  Df Model:          </th>     <td>23</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Jun 2020</td>     <th>  Pseudo R-squ.:     </th>    <td>0.114</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>18:02:10</td>         <th>  Pseudo R-bar-squ.: </th>    <td>0.111</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AIC:</th>                 <td>14,829.660</td>        <th>  Log-Likelihood:    </th> <td>-7,391.830</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIC:</th>                 <td>14,977.906</td>        <th>  LL-Null:           </th> <td>-8,338.849</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                  <td></td>                    <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Price over log(income)</th>       <td>    0.1854</td> <td>    0.027</td> <td>    6.796</td> <td> 0.000</td> <td>    0.132</td> <td>    0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Range (units: 100mi)</th>             <td>    0.3501</td> <td>    0.027</td> <td>   13.052</td> <td> 0.000</td> <td>    0.298</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Acceleration (units: 0.1sec)</th> <td>    0.7160</td> <td>    0.111</td> <td>    6.472</td> <td> 0.000</td> <td>    0.499</td> <td>    0.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Top speed (units: 0.01mph)</th>   <td>    0.2612</td> <td>    0.081</td> <td>    3.228</td> <td> 0.001</td> <td>    0.103</td> <td>    0.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Pollution</th>                    <td>    0.4441</td> <td>    0.102</td> <td>    4.367</td> <td> 0.000</td> <td>    0.245</td> <td>    0.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Size</th>                             <td>    0.9345</td> <td>    0.316</td> <td>    2.953</td> <td> 0.003</td> <td>    0.314</td> <td>    1.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Big enough</th>                       <td>    0.1432</td> <td>    0.077</td> <td>    1.853</td> <td> 0.064</td> <td>   -0.008</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Luggage space</th>                    <td>    0.5009</td> <td>    0.191</td> <td>    2.623</td> <td> 0.009</td> <td>    0.127</td> <td>    0.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Neg Operation cost</th>               <td>    0.7679</td> <td>    0.076</td> <td>   10.131</td> <td> 0.000</td> <td>    0.619</td> <td>    0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Station availability</th>             <td>    0.4133</td> <td>    0.096</td> <td>    4.294</td> <td> 0.000</td> <td>    0.225</td> <td>    0.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sports utility vehicle</th>           <td>    0.8201</td> <td>    0.141</td> <td>    5.830</td> <td> 0.000</td> <td>    0.544</td> <td>    1.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sports car</th>                       <td>    0.6370</td> <td>    0.148</td> <td>    4.298</td> <td> 0.000</td> <td>    0.347</td> <td>    0.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Station wagon</th>                    <td>   -1.4367</td> <td>    0.062</td> <td>  -23.139</td> <td> 0.000</td> <td>   -1.558</td> <td>   -1.315</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Truck</th>                            <td>   -1.0168</td> <td>    0.049</td> <td>  -20.753</td> <td> 0.000</td> <td>   -1.113</td> <td>   -0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Van</th>                              <td>   -0.7989</td> <td>    0.047</td> <td>  -16.864</td> <td> 0.000</td> <td>   -0.892</td> <td>   -0.706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EV</th>                               <td>   -0.1786</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Commute < 5 & EV</th>                 <td>    0.1983</td> <td>    0.084</td> <td>    2.374</td> <td> 0.018</td> <td>    0.035</td> <td>    0.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>College & EV</th>                     <td>    0.4426</td> <td>    0.109</td> <td>    4.058</td> <td> 0.000</td> <td>    0.229</td> <td>    0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CNG</th>                              <td>    0.3450</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Methanol</th>                         <td>    0.3134</td> <td>    0.103</td> <td>    3.051</td> <td> 0.002</td> <td>    0.112</td> <td>    0.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>College & Methanol</th>               <td>    0.2284</td> <td>    0.089</td> <td>    2.576</td> <td> 0.010</td> <td>    0.055</td> <td>    0.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Non Electric-Vehicle</th>             <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Non Compressed Natural Gas</th>       <td>         0</td> <td>      nan</td> <td>      nan</td> <td>   nan</td> <td>      nan</td> <td>      nan</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                     Multinomial Logit Model Regression Results                    \n",
       "===================================================================================\n",
       "Dep. Variable:                      choice   No. Observations:                4,654\n",
       "Model:             Multinomial Logit Model   Df Residuals:                    4,631\n",
       "Method:                                MLE   Df Model:                           23\n",
       "Date:                     Fri, 12 Jun 2020   Pseudo R-squ.:                   0.114\n",
       "Time:                             18:02:10   Pseudo R-bar-squ.:               0.111\n",
       "AIC:                            14,829.660   Log-Likelihood:             -7,391.830\n",
       "BIC:                            14,977.906   LL-Null:                    -8,338.849\n",
       "====================================================================================================\n",
       "                                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------\n",
       "Neg Price over log(income)           0.1854      0.027      6.796      0.000       0.132       0.239\n",
       "Range (units: 100mi)                 0.3501      0.027     13.052      0.000       0.298       0.403\n",
       "Neg Acceleration (units: 0.1sec)     0.7160      0.111      6.472      0.000       0.499       0.933\n",
       "Neg Top speed (units: 0.01mph)       0.2612      0.081      3.228      0.001       0.103       0.420\n",
       "Neg Pollution                        0.4441      0.102      4.367      0.000       0.245       0.643\n",
       "Size                                 0.9345      0.316      2.953      0.003       0.314       1.555\n",
       "Big enough                           0.1432      0.077      1.853      0.064      -0.008       0.295\n",
       "Luggage space                        0.5009      0.191      2.623      0.009       0.127       0.875\n",
       "Neg Operation cost                   0.7679      0.076     10.131      0.000       0.619       0.916\n",
       "Station availability                 0.4133      0.096      4.294      0.000       0.225       0.602\n",
       "Sports utility vehicle               0.8201      0.141      5.830      0.000       0.544       1.096\n",
       "Sports car                           0.6370      0.148      4.298      0.000       0.347       0.928\n",
       "Station wagon                       -1.4367      0.062    -23.139      0.000      -1.558      -1.315\n",
       "Truck                               -1.0168      0.049    -20.753      0.000      -1.113      -0.921\n",
       "Van                                 -0.7989      0.047    -16.864      0.000      -0.892      -0.706\n",
       "EV                                  -0.1786        nan        nan        nan         nan         nan\n",
       "Commute < 5 & EV                     0.1983      0.084      2.374      0.018       0.035       0.362\n",
       "College & EV                         0.4426      0.109      4.058      0.000       0.229       0.656\n",
       "CNG                                  0.3450        nan        nan        nan         nan         nan\n",
       "Methanol                             0.3134      0.103      3.051      0.002       0.112       0.515\n",
       "College & Methanol                   0.2284      0.089      2.576      0.010       0.055       0.402\n",
       "Non Electric-Vehicle                      0        nan        nan        nan         nan         nan\n",
       "Non Compressed Natural Gas                0        nan        nan        nan         nan         nan\n",
       "====================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a MNL with the same design matirx as the MIXL.\n",
    "mnl_model =\\\n",
    "    pl.create_choice_model(data=car_df,\n",
    "                           alt_id_col=ALT_ID_COLUMN,\n",
    "                           obs_id_col=OBS_ID_COLUMN,\n",
    "                           choice_col=CHOICE_COLUMN,\n",
    "                           specification=mnl_spec,\n",
    "                           model_type='MNL',\n",
    "                           names=mnl_names)\n",
    "\n",
    "# Estimate the model to note reproduction of\n",
    "# Brownstone & Train's MNL\n",
    "mnl_model.fit_mle(np.zeros(len(mnl_names)),\n",
    "                  constrained_pos=[-2, -1])\n",
    "\n",
    "# Look at the estimation results\n",
    "mnl_model.get_statsmodels_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the MIXL model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "mixl_model = mixlb.MIXLB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create objects for probability and loss calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target variables for the loss function\n",
    "torch_choices =\\\n",
    "    torch.from_numpy(mnl_model.choices.astype(np.float32)).double()\n",
    "\n",
    "# Get the design matrix from the original and forecast data\n",
    "orig_design_matrix_np = mnl_model.design\n",
    "orig_design_matrix =\\\n",
    "    torch.tensor(orig_design_matrix_np.astype(np.float32))\n",
    "\n",
    "# Get the rows_to_obs and rows_to_mixers matrices.\n",
    "rows_to_obs =\\\n",
    "    utils.create_sparse_mapping_torch(car_df[mnl_model.obs_id_col].values)\n",
    "rows_to_mixers =\\\n",
    "    utils.create_sparse_mapping_torch(car_df[mnl_model.obs_id_col].values)\n",
    "\n",
    "####\n",
    "# Get the normal random variates.\n",
    "####\n",
    "# Determine the number of draws being used for the mixed logit\n",
    "num_draws = 250\n",
    "# Determine the number of observations with randomly distributed\n",
    "# sensitivities\n",
    "num_mixers = car_df.obs_id.unique().size\n",
    "\n",
    "# Get the random draws needed for the draws of each coeffcient\n",
    "# Each element in the list will be a 2D ndarray of shape\n",
    "# num_mixers by num_draws\n",
    "normal_rvs_list_np =\\\n",
    "    mlc.get_normal_draws(num_mixers,\n",
    "                         num_draws,\n",
    "                         mixl_model.design_info.num_mixing_vars,\n",
    "                         seed=601)\n",
    "normal_rvs_list = [torch.from_numpy(x).double() for x in normal_rvs_list_np]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the objective function\n",
    "Create the function to be used by `scipy.optimize.minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scipy_closure(\n",
    "        design,\n",
    "        obs_mapping,\n",
    "        mixers_mapping,\n",
    "        normal_draws,\n",
    "        targets,\n",
    "        model,\n",
    "        loss_func,\n",
    "        ):\n",
    "    def closure(params):\n",
    "        # params -> loss, grad\n",
    "        # Load the parameters onto the model\n",
    "        model.set_params_numpy(params)\n",
    "        # Ensure the gradients are summed starting from zero\n",
    "        model.zero_grad()\n",
    "        # Calculate the probabilities\n",
    "        probabilities =\\\n",
    "            model(design_2d=design,\n",
    "                  rows_to_obs=obs_mapping,\n",
    "                  rows_to_mixers=mixers_mapping,\n",
    "                  normal_rvs_list=normal_draws)\n",
    "        # Calculate the loss\n",
    "        loss = loss_func(probabilities, targets)\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Get the gradient.\n",
    "        grad = model.get_grad_numpy()\n",
    "        # Get a value of the loss to pass around.\n",
    "        loss_val = loss.item()\n",
    "        return loss_val, grad\n",
    "    return closure\n",
    "\n",
    "scipy_objective =\\\n",
    "    make_scipy_closure(orig_design_matrix,\n",
    "                       rows_to_obs,\n",
    "                       rows_to_mixers,\n",
    "                       normal_rvs_list,\n",
    "                       torch_choices,\n",
    "                       mixl_model,\n",
    "                       utils.log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimate MIXLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n",
    "# Initialize parameters\n",
    "####\n",
    "# Initialize the model parameters to the final estimates from Brownstone & Train (1998),\n",
    "# taking care of the typo from the published paper.\n",
    "mean_array =\\\n",
    "    np.array([-1.5983748481622846, #-5.999,\n",
    "              -0.877,\n",
    "              -0.302,\n",
    "              -1.364,\n",
    "              -0.711,\n",
    "               1.541,\n",
    "              -1.748,\n",
    "               1.563,\n",
    "              -0.071,\n",
    "              -0.741,\n",
    "               0.897,\n",
    "               0.698,\n",
    "              -1.508,\n",
    "              -1.094,\n",
    "              -0.819,\n",
    "              -0.905,\n",
    "               0.359,\n",
    "               0.770,\n",
    "               0.621,\n",
    "               0.476,\n",
    "               0.335,\n",
    "               0,\n",
    "               0])\n",
    "\n",
    "std_dev_array =\\\n",
    "    np.array([6.808, 5.380, 2.289, 0.971])\n",
    "\n",
    "paper_estimates_array =\\\n",
    "    np.concatenate((mean_array, std_dev_array), axis=0)\n",
    "\n",
    "# Set the parameters on the model\n",
    "mixl_model.set_params_numpy(paper_estimates_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial MIXL: -7,370.09\n",
      "MNL:          -7,391.83\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "# Compute initial log-likelihood\n",
    "####\n",
    "with torch.no_grad():\n",
    "    # Compute the MIXL probabilities\n",
    "    initial_mixl_probs =\\\n",
    "        mixl_model.forward(design_2d=orig_design_matrix,\n",
    "                           rows_to_obs=rows_to_obs,\n",
    "                           rows_to_mixers=rows_to_mixers,\n",
    "                           normal_rvs_list=normal_rvs_list)\n",
    "\n",
    "    # Compute the MIXL log-likelihood\n",
    "    initial_mixl_log_likelihood =\\\n",
    "        -1 * utils.log_loss(initial_mixl_probs, torch_choices)\n",
    "\n",
    "    # Compare the MIXL to MNL log-likelihoods\n",
    "    msg = 'Initial MIXL: {:,.2f}\\nMNL:          {:,.2f}'\n",
    "    print(msg.format(initial_mixl_log_likelihood.item(), mnl_model.llf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation Time: 10.8 minutes\n"
     ]
    }
   ],
   "source": [
    "# Perform the optimization\n",
    "start_time = time.time()\n",
    "\n",
    "optimization_results =\\\n",
    "    minimize(scipy_objective,\n",
    "             paper_estimates_array,\n",
    "             jac=True,\n",
    "             method='bfgs')\n",
    "\n",
    "end_time = time.time()\n",
    "duration_sec = end_time - start_time\n",
    "duration_mins = duration_sec / 60.\n",
    "\n",
    "print('Estimation Time: {:.1f} minutes'.format(duration_mins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Log-likelihood: -7,370.09\n",
      "Final Log-Likelihood:    7,366.56\n"
     ]
    }
   ],
   "source": [
    "print('Initial Log-likelihood: {:,.2f}'.format(initial_mixl_log_likelihood))\n",
    "print('Final Log-Likelihood:    {:,.2f}'.format(optimization_results['fun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.02063929e-10,  1.61201999e-07, -4.19390302e-08,  7.47850686e-08,\n",
       "       -1.82699654e-07,  3.43704994e-08, -1.54603583e-07, -5.11718366e-08,\n",
       "       -1.05335401e-08,  2.53901248e-07,  1.07174357e-08,  6.49821302e-09,\n",
       "        2.32708658e-08,  4.43429601e-08, -1.78816608e-08,  3.17923849e-08,\n",
       "        4.95778456e-08, -1.71724781e-08,  7.90312933e-09, -2.53907315e-07,\n",
       "       -2.36296594e-07,  0.00000000e+00,  0.00000000e+00, -2.60114483e-08,\n",
       "       -3.65452061e-08,  1.77963963e-08,  9.52168868e-08])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the gradient at the final parameters\n",
    "optimization_results['jac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.598375</td>\n",
       "      <td>-1.511420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.877000</td>\n",
       "      <td>-0.741690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.302000</td>\n",
       "      <td>-0.291876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364000</td>\n",
       "      <td>-1.472323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.711000</td>\n",
       "      <td>-0.655299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.541000</td>\n",
       "      <td>1.735805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.748000</td>\n",
       "      <td>-1.609506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.563000</td>\n",
       "      <td>1.505530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-0.027687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.741000</td>\n",
       "      <td>-0.539973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.897000</td>\n",
       "      <td>0.919872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.698000</td>\n",
       "      <td>0.703151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1.508000</td>\n",
       "      <td>-1.510915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-1.094000</td>\n",
       "      <td>-1.104511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.819000</td>\n",
       "      <td>-0.816081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.905000</td>\n",
       "      <td>-0.873168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.359000</td>\n",
       "      <td>0.394959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.830615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.621000</td>\n",
       "      <td>0.586968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.476000</td>\n",
       "      <td>0.614815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.365396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6.808000</td>\n",
       "      <td>8.423692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.380000</td>\n",
       "      <td>5.093928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.289000</td>\n",
       "      <td>2.524102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.971000</td>\n",
       "      <td>1.390528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     initial     final\n",
       "0  -1.598375 -1.511420\n",
       "1  -0.877000 -0.741690\n",
       "2  -0.302000 -0.291876\n",
       "3  -1.364000 -1.472323\n",
       "4  -0.711000 -0.655299\n",
       "5   1.541000  1.735805\n",
       "6  -1.748000 -1.609506\n",
       "7   1.563000  1.505530\n",
       "8  -0.071000 -0.027687\n",
       "9  -0.741000 -0.539973\n",
       "10  0.897000  0.919872\n",
       "11  0.698000  0.703151\n",
       "12 -1.508000 -1.510915\n",
       "13 -1.094000 -1.104511\n",
       "14 -0.819000 -0.816081\n",
       "15 -0.905000 -0.873168\n",
       "16  0.359000  0.394959\n",
       "17  0.770000  0.830615\n",
       "18  0.621000  0.586968\n",
       "19  0.476000  0.614815\n",
       "20  0.335000  0.365396\n",
       "21  0.000000  0.000000\n",
       "22  0.000000  0.000000\n",
       "23  6.808000  8.423692\n",
       "24  5.380000  5.093928\n",
       "25  2.289000  2.524102\n",
       "26  0.971000  1.390528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the final parameters to their starting values\n",
    "estimates_df =\\\n",
    "    pd.DataFrame({'initial': paper_estimates_array,\n",
    "                  'final': optimization_results['x']})\n",
    "estimates_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian Computation: 18.8 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get rid of old gradient computations\n",
    "mixl_model.zero_grad()\n",
    "\n",
    "# Compute final probabilities\n",
    "final_mixl_probs =\\\n",
    "    mixl_model(design_2d=orig_design_matrix,\n",
    "               rows_to_obs=rows_to_obs,\n",
    "               rows_to_mixers=rows_to_mixers,\n",
    "               normal_rvs_list=normal_rvs_list)\n",
    "\n",
    "# Compute final loss\n",
    "final_log_likelihood =\\\n",
    "    utils.log_loss(final_mixl_probs, torch_choices)\n",
    "\n",
    "# Compute the hessian of the loss\n",
    "hess_start_time = time.time()\n",
    "final_mixlb_hessian =\\\n",
    "    hessian(final_log_likelihood,\n",
    "            mixl_model.parameters())\n",
    "hess_end_time = time.time()\n",
    "hess_duration_sec = hess_end_time - hess_start_time\n",
    "hess_duration_mins = hess_duration_sec / 60.\n",
    "print('Hessian Computation: {:.1f} minutes'.format(hess_duration_mins))\n",
    "\n",
    "# Get the numpy array corresponding to the hessian\n",
    "final_mixlb_hessian_array = final_mixlb_hessian.numpy()\n",
    "\n",
    "# Extract the hessian that excludes the rows and columns\n",
    "# for the two constrained parameters\n",
    "desired_rows =\\\n",
    "    np.concatenate((np.arange(0, 21), np.arange(23, 27)), axis=0)\n",
    "final_mixlb_hessian_core =\\\n",
    "    final_mixlb_hessian_array[np.ix_(desired_rows, desired_rows)]\n",
    "final_mixlb_hessian_core.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final parameters\n",
    "estimates_df.final.to_csv(OUTPUT_PARAM_PATH, index=False)\n",
    "# Save the final gradient\n",
    "(pd.Series(optimization_results['jac'])\n",
    "   .to_csv(OUTPUT_GRADIENT_PATH, index=False))\n",
    "# Save the final hessian\n",
    "(pd.DataFrame(final_mixlb_hessian_array)\n",
    "   .to_csv(OUTPUT_HESSIAN_PATH, index=False, header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "1. The most unexpected finding was that none of the parameter gradients was near zero when using the parameter values from the published article.\n",
    "\n",
    "2. When optimizing the model to get to a true local maximum of the log-likelihood function, there does not seem to be a huge difference in final results.\n",
    "The largest parameter change is the increase in the variance of non-EV utility functions.\n",
    "\n",
    "3. Computing the hessian of the estimated parameters takes a **very** long time.\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
